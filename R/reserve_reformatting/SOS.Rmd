---
title: "South Slough"
author: "Kim Cressman"
date: "2022-08-16; latest update 2023-03-08"
output: 
    html_document:
        toc: true
        toc_depth: 2
        code_folding: hide
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
```

```{r}
library(tidyverse)
library(readxl)
library(writexl)
library(leaflet)
library(rgdal)
library(stringi)  # for stri_sub_replace()

reserve <- "SOS"
```

# Setup  

## Helpful functions  

Because I'll be doing this repetitively on similar data files....  

```{r}
source(here::here("R", "sourced", "00_helper_functions.R"))
```

## Data path  

Update for each reserve: all start at  `here::here("submitted_data", "data")` but it varies by reserve.   

Also create an output folder for each reserve in the `wrangled data` folder and update the `path_out` below.  

```{r}
path_start <- here::here("submitted_data", "data", reserve)
problem_path_out <- here::here("wrangled_data", "combined_with_issues")
path_out <- here::here("wrangled_data", "CDMO")

# create the output folder if it doesn't already exist
if(!dir.exists(path_out)){
    dir.create(path_out)
}
```

**South Slough only has 2 main files, but lots of worksheets.**  

+  `SOS_PercCov_2010_2021.xlsx` - format of sheets is SOSyyyy: SOS2011, SOS2015, etc. Formatted in CDMO style.  
+  `SOS_StemCt_Ht_2010_2021.xlsx` - wide format, with counts and heights (multiple columns for height). Also has worksheet to decode plant acronyms. 

Define the worksheets   

```{r}
book <- here::here(path_start, "SOS_PercCov_2010_2021.xlsx") 
sheets <- excel_sheets(book)
```



Read into a list and combine  **MODIFY FOR DIFFERENT DATA TYPES**  

# CDMO formatted input  

This section will compile code to read in and combine files that are already in CDMO format. Then a long CDMO-format file will be generated, after reconciling column names, dates, and putting things in order. The NaMaSTe template file will be generated from the CDMO-format file.  

```{r}
dat_in <- list()

for(i in seq_along(sheets)){
    dat_in[[i]] <- read_cdmo(here::here(book),
                             worksheet = sheets[i],
                             skip = 3) %>% 
        mutate(PlotID = as.character(PlotID),
               TransectID = as.character(TransectID))
}

# find out if any columns aren't the same type
janitor::compare_df_cols_same(dat_in)

dat_all <- bind_rows(dat_in)
```

PlotID and TransectID had to be formatted as character. PlotID had a value of `x` in Transect4 at site FS, only in one instance in 2019 in original file; this has been fixed in a re-submitted file. TransectID has `M` and `S` in 2010 only at site DM; these are real transects that were only measured that year.  


# Checks  

## Column names and types?  

Look for different column names for the same thing.  

```{r}
names(dat_all)
```

## Duplicates in date-site-transect-plot-species  

Include subplot if used by reserve. Want an empty tibble below.    

```{r}
unique(dat_all$Subplot)

janitor::get_dupes(dat_all, Date, SiteID, TransectID, PlotID, Species) %>% View()
```


## Check station/plot names  

```{r}
unique(dat_all$Reserve)
```

```{r}
dat_all %>% 
    select(Reserve, SiteID, TransectID, PlotID) %>% 
    distinct() %>% 
    knitr::kable()
```


### 'Distance' discrepancies  

```{r}
stn_dupes <- dat_all %>% 
    select(Reserve, SiteID, TransectID, PlotID,
           Distance) %>% 
    distinct() %>% 
    janitor::get_dupes(-Distance)

stn_dupes
```

Different distances for plots - must measure every time.  

### Lat/Long discrepancies  



## Mangroves or SAV present?  

Mangrove species are: *Avicennia germinans*, *Laguncularia racemosa*, *Rhizophora mangle*. Check for these before discarding a `Height` or `Diameter` column.   

The following sums will be 0 if none of the genus names were found in the species column. This is only set to detect the first few letteres in case of misspellings, so if any sums are above 0, it deserves further investigation.  

```{r}
spp_all <- sort(unique(dat_all$Species))
knitr::kable(spp_all)
sum(str_detect(spp_all, "Avic"))
sum(str_detect(spp_all, "Lagunc"))
sum(str_detect(spp_all, "Rhizo"))

```

Also check for anything other than 'E' in 'Type'.

```{r}
unique(dat_all$Type)
```

## Check species names  

```{r}
dat_all$Species <- str_replace(dat_all$Species, pattern = "  ", replacement = " ")
    
spp <- dat_all %>% 
    group_by(Species) %>% 
    tally()

spp_out_path <- here::here("wrangled_data", "combined_with_issues", paste0(reserve, "_species.csv")) 

# write.csv(spp, spp_out_path, row.names = FALSE)
```

# Fix species names  

I copied the csv written out just above, and inserted a new column "Species_correct" into which I copied all of the original species, and updated misspelled ones to the correct spellings. Can do a full join and rename of this to get all species corrected in the data frame.  

```{r}
spp_correct <- read.csv(here::here("wrangled_data", "combined_with_issues", "SOS_species_corrected.csv")) %>% 
    select(-n)

dat_all <- left_join(dat_all, spp_correct) %>% 
    select(-Species) %>% 
    rename(Species = Species_correct) %>% 
    relocate(Species, .before = Cover)
```


# Get rid of exactly duplicated rows  

this gets rid of 191 rows  

```{r}
dat_all <- dat_all %>% 
    distinct()

# check for dupes again
dat_all %>%
   group_by(Date, SiteID, TransectID, PlotID,  Species) %>%
    tally() %>%
    filter(n > 1) %>%
    select(Date:Species, n)

cover_discreps <- dat_all %>% 
    janitor::get_dupes(-Cover) %>% 
    select(Date, SiteID, TransectID, PlotID,  Species, Cover)
# all good now

# write.csv(cover_discreps,
#           here::here("wrangled_data", "combined_with_issues", 
#                      "SOS_dupes_discrepancies.csv"),
#           row.names = FALSE)
```



# Bring in lat/long  

Lat, long, and elevations are measured on a different timeline than veg data - for at least one site (FS), cover measurements were taken in July and elevation/lat/long measurements in September of a couple different years. Not sure whether I should tie these together then.....  

```{r}
coords <- read_xlsx(here::here(path_start,  
                               "SOS_Elevations_2010_2021.xlsx")) %>% 
    select(SiteID = Site,
           TransectID,
           PlotID,
           Date = Date_Obs,
           Lat = LocalLatit,
           Long = LocalLongi,
           Orthometric_Height = `Elevation (m; NAVD88)`) %>% 
    mutate(Reserve = "SOS",
           Date_excel = as.numeric(case_when(!str_detect(Date, "/") ~ Date,
                                             TRUE ~ NA_character_)),
           Date_mdy = case_when(str_detect(Date, "/") ~ Date,
                                TRUE ~ NA_character_),
           Date = case_when(!is.na(Date_excel) ~ janitor::excel_numeric_to_date(Date_excel),
                            !is.na(Date_mdy) ~ lubridate::mdy(Date_mdy))) %>% 
    select(-Date_excel, -Date_mdy)

# dat_all2 <- full_join(dat_all, coords) %>% 
#     relocate(Lat, .after = "SSAM-1") %>% 
#     relocate(Long, .after = Lat)
# 
# dat_all2 %>% arrange(Date) %>% View()

```


# Bring in density and heights workbook  

```{r}
dens_ht <- read_xlsx(here::here(path_start, "SOS_StemCt_Ht_2010_2021.xlsx"),
                     sheet = "Stem_counts_and_heights")
abbrevs <- read_xlsx(here::here(path_start, "SOS_StemCt_Ht_2010_2021.xlsx"),
                     sheet = "Plant Acronyms")
names(abbrevs) <- c("code", "Species")
```

Issues to fix:  

+  Date is sometimes mm/dd/yyyy and other times Excel's date format. Split these out and unify.  
+  per 1/10/2023 emails with Alice: Site DP (in dens/ht file) is the same site as Site DM (in Pct_cover file). Updating DP to DM here.  
+  also found 1/10/2023: Year column is present in dens_ht spreadsheet, and the way I handled the data, it's causing Year.X and Year.Y columns during the join (shouldn't they match???) In any case, getting rid of that column here.  
+  Sometimes dates of density/height measurements are different from the dates when cover was measured. In 2010 and 2011, this was due to methodological differences. In 2015 and 2020, these are typos.  
    +  Fixing 2015 and 2020 dates based on what Jenni sent 1/11/23. Will do this after data frames are joined; can do a case_when so that if year is 2015 or 2020, Date_HtDens = Date.    
    +  Calling column in this data frame "Date_HtDens" to differentiate from Cover date, but still allow joining by year.  

```{r}
dens_ht <- dens_ht %>% 
    select(-Year) %>% 
    mutate(Date_excel = as.numeric(case_when(!str_detect(Date, "/") ~ Date,
                                             TRUE ~ NA_character_)),
           Date_mdy = case_when(str_detect(Date, "/") ~ Date,
                                TRUE ~ NA_character_),
           Date = case_when(!is.na(Date_excel) ~ janitor::excel_numeric_to_date(Date_excel),
                            !is.na(Date_mdy) ~ lubridate::mdy(Date_mdy)),
           across(c(`AGRSTO ct`:`OENSAR ht3`), as.numeric),
           TransectID = as.character(TransectID),
           PlotID = as.character(PlotID),
           Site = case_when(Site == "DP" ~ "DM",
                            TRUE ~ Site),
           Year = lubridate::year(Date)) %>% 
    rename(SiteID = Site,
           Date_HtDens = Date) %>% 
    select(-Date_excel, -Date_mdy)
```

## Split out density and height  

```{r}
all_names <- names(dens_ht)
dens_names <- all_names[str_ends(all_names, pattern = " ct")]
ht_names <- all_names[str_ends(all_names, pattern = " ht[1-3]")]

dens <- dens_ht %>% 
    select(ID:Date_HtDens, Year, "Notes" = NOTES, all_of(dens_names)) %>% 
    pivot_longer(-(ID:Notes), 
                 names_to = c("code", "param"), 
                 names_sep = " ",
                 values_to = "Density") %>% 
    filter(!is.na(Density)) %>% 
    full_join(abbrevs) %>% 
    select(-code, -param) %>% 
    relocate(Species, .before = Density)
    
hts <- dens_ht %>% 
    select(ID:Date_HtDens, Year, "Notes" = NOTES, all_of(ht_names))%>% 
    pivot_longer(-(ID:Notes), 
                 names_to = c("code", "param"), 
                 names_sep = " ",
                 values_to = "Height") %>% 
    filter(!is.na(Height)) %>%
    group_by(SiteID, TransectID, PlotID, Date_HtDens, Year, code) %>% 
    summarize(Height = mean(Height)) %>% 
    full_join(abbrevs) %>% 
    select(-code) %>% 
    relocate(Species, .before = Height)
```


## Add density and height to CDMO-formatted data frame  

```{r}
# dat_all %>% janitor::get_dupes(SiteID, TransectID, PlotID, Species, Date) %>% View()

# create year column in dat_all first - safer to do here than above given all the code that's already run  

dat_all <- dat_all %>% 
    mutate(Year = lubridate::year(Date)) %>% 
    relocate(Year, .after = Date)


# pull out heights that don't have corresponding entries in the cover data frame
ht_uniques <- anti_join(hts, dat_all)
# pull out info about each site/transect/plot/date combo and join it with those unique values so they have all the assoicated plot metadata
ht_uniques_filledin <- dat_all %>% 
    select(-Species, -Cover) %>% 
    distinct() %>% 
    right_join(ht_uniques) # %>% View()

# same as height data frame stuff, but on density
dens_uniques <- anti_join(dens, dat_all)
dens_uniques_filledin <- dat_all %>% 
    select(-Species, -Cover) %>% 
    distinct() %>% 
    right_join(dens_uniques)

# join height and density uniques (no entry in 'cover') together, because 2 match
htdens_uniques <- full_join(ht_uniques_filledin, dens_uniques_filledin)

# join the matching height and density data frames to cover,
# then bind the height and density uniques from above
dat_all2 <- dat_all %>% 
    left_join(hts, by = c("SiteID", "TransectID", "PlotID", "Species", "Year")) %>% 
    left_join(dens, by = c("SiteID", "TransectID", "PlotID", "Species", "Year", "Date_HtDens")) %>% 
    bind_rows(htdens_uniques) %>% 
    arrange(Year, SiteID, TransectID, PlotID, Species)

# make sure nothing got inadvertently duplicated (all good)
# janitor::get_dupes(dat_all2, SiteID, TransectID, PlotID, Year, Species)

dat_all <- dat_all2
```


```{r}
# testing joins while trying to figure out the above


# test <- dat_all2 %>% filter(is.na(Reserve))
# write_xlsx(test, here::here("wrangled_data", "combined_with_issues", "SOS_HtDens_noCover.xlsx"))

# non_matching <- dat_all_problem_version %>% 
#     filter(is.na(Reserve))
# 
# sum(is.na(dat_all$Reserve))  # 0 - so the hts/dens records aren't matching with existing Site/Transect/Plot/Species/Date combos

# is it sites or dates that don't match? Because there aren't dupes for the other ID columns....

# dat_all_problems2 <- dat_all_problem_version %>% 
#     mutate(Year = lubridate::year(Date))
# 
# dat_all_problems2 %>% 
#     janitor::get_dupes(SiteID, TransectID, PlotID, Species, Year) %>%
#     View()
# 
# dates_different <- dat_all_problems2 %>% 
#     janitor::get_dupes(SiteID, TransectID, PlotID, Species, Year)
# 
# writexl::write_xlsx(dates_different, here::here("wrangled_data",
#                                                 "combined_with_issues",
#                                                 "SOS_dates_diff_cov_vs_htdens.xlsx"))
```

Deal with the date issues from 2015 and 2020  

```{r}
# test <- dat_all %>% filter(!is.na(Date_HtDens), Year %in% c(2015, 2020))
# sum(test$Date != test$Date_HtDens)

# weird things happened filtering after doing case_when on the dates directly
# but it was okay when I converted them to character first
# so that's how I'm replacing the wrong HtDens dates in 2015 and 2020
dat_all2 <- dat_all %>% 
    mutate(across(c(Date, Date_HtDens), as.character),
           Date_HtDens = case_when(Year %in% c(2015, 2020) ~ Date,
                                    TRUE ~ Date_HtDens),
           across(c(Date, Date_HtDens), as.Date))

dat_all <- dat_all2


# test <- dat_all2 %>% filter(!is.na(Date_HtDens), Year %in% c(2015, 2020))
# sum(test$Date != test$Date_HtDens)
```


# Join lat/long and elevation in a similar way to dens/ht  

With a new column for Date_GPS  

```{r}
coords_to_join <- coords %>% 
    filter(PlotID != "NA") %>% 
    mutate(Year = lubridate::year(Date),
           Date_GPS = Date) %>% 
    select(-Date, -Reserve)
```

```{r}
janitor::get_dupes(coords_to_join, SiteID, TransectID, PlotID, Year) %>% View()
```


There's a dupe in here, for 2016, FS, 3, 2, with different elevation values. Looking back at the raw files, these rows have different "plot_nom" identifiers. The larger value (2.491034) belongs to "q5w", which should be plot 1 (not 2). Cross-checked with Q5W in the height/density file. Fixing.  

```{r}
to_fix <- coords_to_join %>% 
    mutate(rownum = row_number()) %>% 
    filter(SiteID == "FS",
           TransectID == "3",
           PlotID == "2",
           Year == 2016)

coords_to_join$PlotID[to_fix$rownum[2]] <- "1"
```

## JOIN  

```{r}
dat_all <- left_join(dat_all, coords_to_join)
```

NOTE not all elevation data were joined; this was a left-join so the data were added to the main table only if cover data were present for the year that elevation was measured. This means 2011 elevations were not included.  

# IMPORTANT NOTES FOR THIS RESERVE  

Will average heights to get into CDMO format. Will insert density where it belongs. WHEN MAKING THE NAMASTE TEMPLATE, need to come back to this to get the REPLICATES OF HEIGHT DATA.  


# Fix discrepancies  


## Column wrangling  



## CDMO format (long)  

CDMO column names, in order. If columns had different names, or there were additional ones, account for that here.    

```{r}
# add in missing columns
dat_all <- dat_all %>% 
    mutate(Subplot = glue::glue("{Plot_nom} - {`Subplot locator`}",
                                .na = ""),
           Subplot = ifelse(Subplot == " - ", NA_character_, Subplot),
           Rep = NA,
           "Height Relative to MLLW" = NA,
           QAQC = NA_character_)

# ADD QAQC CODES WHEN DATES DIDN'T MATCH
dat_all$QAQC[which(dat_all$Date != dat_all$Date_HtDens)] <- "0 CSM"
```

Pull out columns for Month, Day, and Year; and format Date as mm/dd/yyyy for the CDMO output file.  

```{r}
dat_all <- dat_all %>% 
    mutate(
        Month = lubridate::month(Date),
        Day = lubridate::mday(Date),
        Date = format(Date, "%m/%d/%Y")
    ) 
```

```{r}

dat_cdmo <- dat_all %>% 
    select(
        "Reserve",
        "Type",
        "Date",
        "Year",
        "Month",
        "Day",
        "Date_HtDens",
        "Date_GPS",
        "SiteID",
        "TransectID",
        "PlotID",
        "Subplot",
        "Rep",
        "SSAM-1",
        "Lat",
        "Long",
        "Distance",
        "Orthometric Height" = Orthometric_Height,
        "Height Relative to MLLW",
        "Notes",
        "Species",
        "Cover",
        "Density",
        "Maximum Canopy Height" = Height,
        "QAQC"
    ) %>% 
    arrange(Year, Month, Day, SiteID, TransectID, PlotID, Species)
```


## Write the CDMO data frame to a file. **Modify for each reserve**  

```{r}
# write.csv(dat_cdmo, here::here(problem_path_out, paste0(reserve, "_issues.csv")), 
#           row.names= FALSE,
#           na = "")
```

```{r}
write_xlsx(dat_cdmo, path = here::here(path_out, paste0(reserve, "_CDMO.xlsx")),
           format_headers = TRUE)
```


# NaMaSTe tables  

Get rid of any NAs in lat/long; we want station characteristics.  

```{r}
station_table <- dat_cdmo %>% 
    select(Reserve,
           SiteID,
           TransectID,
           PlotID,
           Lat,
           Long,
           Type,
           "SSAM-1") %>% 
    distinct() %>% 
    arrange(SiteID, TransectID, PlotID)
```

Do any plots have multiple rows?  

```{r}
station_table %>% 
    group_by(Reserve, SiteID, TransectID, PlotID) %>% 
    tally() %>% 
    arrange(desc(n)) %>% 
    head() %>% 
    knitr::kable()
```

Are all stations actually represented? If the below output is FALSE, there's a problem to fix. If TRUE, proceed.     

```{r}
stns_all <- dat_cdmo %>% 
    select(Reserve, SiteID, TransectID, PlotID) %>% 
    distinct()

nrow(stns_all) == nrow(station_table)
```